{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas\n",
    "import gensim\n",
    "import collections\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "DATA_FILE = '../data/all_titles_sw.txt.gz'\n",
    "EMBEDDING_OUT_PATH = '../w2v/embeddings/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(DATA_FILE, 'rb') as f:\n",
    "    file_content = f.read()\n",
    "all_sentences = file_content.decode('utf-8').split('\\n')\n",
    "sw_path = os.path.abspath(\"../stopwords.txt\")\n",
    "sw = stopwords.words(sw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['corneal',\n",
       "  'endothelial',\n",
       "  'deposits',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'rifabutin',\n",
       "  'use']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "all_sentences  = list(sent_to_words(all_sentences))\n",
    "all_sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(bigram, texts):\n",
    "    return [bigram[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trigrams(bigram, trigram, texts):\n",
    "    return [trigram[bigram[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = Phrases(all_sentences, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = Phrases(bigram[all_sentences], threshold=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ngrams = make_bigrams(bigram, all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ngrams = make_trigrams(bigram, trigram, all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160491"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422774"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for word in data_ngrams:\n",
    "    for i in word:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for data with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('brazil', 144894),\n",
       "             ('study', 106474),\n",
       "             ('analysis', 88876),\n",
       "             ('effects', 85923),\n",
       "             ('brazilian', 81035),\n",
       "             ('patients', 78301),\n",
       "             ('evaluation', 62146),\n",
       "             ('activity', 60475),\n",
       "             ('rats', 53699),\n",
       "             ('properties', 47204)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = collections.OrderedDict([line for line in sorted(word_freq.items(), key=lambda x:x[1], reverse=True) if line[0] not in sw][:10])\n",
    "top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for data without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top10 = collections.OrderedDict(sorted(word_freq.items(), key=lambda x:x[1], reverse=True)[:10])\n",
    "#top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(data_ngrams, \n",
    "                 min_count=3,   # Ignore words that appear less than this\n",
    "                 size=300,      # Dimensionality of word embeddings\n",
    "                 workers=10,     # Number of processors (parallelisation)\n",
    "                 window=5,      # Context window for words during training\n",
    "                 iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224630"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wireless_networks', 0.5335965752601624),\n",
       " ('wireless_sensor_networks', 0.5160489082336426),\n",
       " ('wireless_sensor', 0.4690731167793274),\n",
       " ('bluetooth', 0.4526071846485138),\n",
       " ('ieee', 0.4511309266090393),\n",
       " ('reconfigurable', 0.4503900408744812),\n",
       " ('mimo', 0.44723522663116455),\n",
       " ('energyefficient', 0.4468957185745239),\n",
       " ('ofdm', 0.4348280429840088),\n",
       " ('wlan', 0.42918577790260315)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='wireless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brazil</th>\n",
       "      <th>study</th>\n",
       "      <th>analysis</th>\n",
       "      <th>effects</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>patients</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>activity</th>\n",
       "      <th>rats</th>\n",
       "      <th>properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(brasil, 0.8688706159591675)</td>\n",
       "      <td>(studies, 0.7355968356132507)</td>\n",
       "      <td>(analyses, 0.7738421559333801)</td>\n",
       "      <td>(effect, 0.9310852289199829)</td>\n",
       "      <td>(brasilian, 0.848153829574585)</td>\n",
       "      <td>(patient, 0.8059606552124023)</td>\n",
       "      <td>(assessment, 0.7546509504318237)</td>\n",
       "      <td>(activities, 0.8008769750595093)</td>\n",
       "      <td>(rat, 0.827140212059021)</td>\n",
       "      <td>(proprieties, 0.6129109859466553)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(brazilian, 0.8031655550003052)</td>\n",
       "      <td>(investigation, 0.6739801168441772)</td>\n",
       "      <td>(analisys, 0.6831382513046265)</td>\n",
       "      <td>(influence, 0.7686419486999512)</td>\n",
       "      <td>(brazil, 0.80316561460495)</td>\n",
       "      <td>(patientes, 0.7938013076782227)</td>\n",
       "      <td>(study, 0.6117603778839111)</td>\n",
       "      <td>(acitivity, 0.5780574083328247)</td>\n",
       "      <td>(mice, 0.7445719242095947)</td>\n",
       "      <td>(property, 0.5564204454421997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(brazi, 0.7469620704650879)</td>\n",
       "      <td>(analysis, 0.6443814039230347)</td>\n",
       "      <td>(study, 0.6443814039230347)</td>\n",
       "      <td>(impact, 0.6441784501075745)</td>\n",
       "      <td>(brasil, 0.6299118995666504)</td>\n",
       "      <td>(individuals, 0.7883312106132507)</td>\n",
       "      <td>(analysis, 0.5995725989341736)</td>\n",
       "      <td>(activityof, 0.570565938949585)</td>\n",
       "      <td>(rabbits, 0.6112174987792969)</td>\n",
       "      <td>(propertiesof, 0.5214764475822449)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(brasilian, 0.6604605913162231)</td>\n",
       "      <td>(evaluation, 0.6117604970932007)</td>\n",
       "      <td>(evaluation, 0.5995726585388184)</td>\n",
       "      <td>(efects, 0.6215373277664185)</td>\n",
       "      <td>(braziliam, 0.6071518659591675)</td>\n",
       "      <td>(subjects, 0.7555750608444214)</td>\n",
       "      <td>(evalution, 0.5922452211380005)</td>\n",
       "      <td>(activies, 0.5061926245689392)</td>\n",
       "      <td>(ratsa, 0.5670409202575684)</td>\n",
       "      <td>(propeties, 0.47726237773895264)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(spain, 0.6341298222541809)</td>\n",
       "      <td>(assessment, 0.5354693531990051)</td>\n",
       "      <td>(assessment, 0.5787420272827148)</td>\n",
       "      <td>(influences, 0.6062849760055542)</td>\n",
       "      <td>(spanish, 0.5729133486747742)</td>\n",
       "      <td>(women, 0.7411853075027466)</td>\n",
       "      <td>(assesment, 0.5624517202377319)</td>\n",
       "      <td>(acivity, 0.48496779799461365)</td>\n",
       "      <td>(mouse, 0.5656639933586121)</td>\n",
       "      <td>(behavior, 0.4641653895378113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(brazilstrongp, 0.6220083236694336)</td>\n",
       "      <td>(investigations, 0.5060980319976807)</td>\n",
       "      <td>(analisis, 0.5593183040618896)</td>\n",
       "      <td>(efect, 0.5589128136634827)</td>\n",
       "      <td>(sao_paulo, 0.5689626932144165)</td>\n",
       "      <td>(children, 0.7381284236907959)</td>\n",
       "      <td>(evaluations, 0.5607291460037231)</td>\n",
       "      <td>(activy, 0.47533169388771057)</td>\n",
       "      <td>(wistar, 0.5301536917686462)</td>\n",
       "      <td>(characteristics, 0.4538622200489044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>(portugal, 0.6136013269424438)</td>\n",
       "      <td>(stydy, 0.48788881301879883)</td>\n",
       "      <td>(investigation, 0.5209058523178101)</td>\n",
       "      <td>(role, 0.4827345013618469)</td>\n",
       "      <td>(brazils, 0.5603929758071899)</td>\n",
       "      <td>(pacients, 0.718267023563385)</td>\n",
       "      <td>(investigation, 0.5300816297531128)</td>\n",
       "      <td>(activiy, 0.46622419357299805)</td>\n",
       "      <td>(rabbit, 0.5016534328460693)</td>\n",
       "      <td>(stability, 0.4474780559539795)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>(brazils, 0.60157310962677)</td>\n",
       "      <td>(sudy, 0.46877536177635193)</td>\n",
       "      <td>(studies, 0.5072707533836365)</td>\n",
       "      <td>(depends, 0.4525492787361145)</td>\n",
       "      <td>(brazillian, 0.5571433305740356)</td>\n",
       "      <td>(outpatients, 0.6770029067993164)</td>\n",
       "      <td>(evaluating, 0.5208792686462402)</td>\n",
       "      <td>(activites, 0.44755539298057556)</td>\n",
       "      <td>(dogs, 0.5006157159805298)</td>\n",
       "      <td>(proprierties, 0.43291914463043213)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(argentina, 0.5932648181915283)</td>\n",
       "      <td>(sutdy, 0.46010395884513855)</td>\n",
       "      <td>(analysys, 0.47804951667785645)</td>\n",
       "      <td>(impacts, 0.43384480476379395)</td>\n",
       "      <td>(latin_american, 0.5461232662200928)</td>\n",
       "      <td>(patiens, 0.643639862537384)</td>\n",
       "      <td>(assessing, 0.4701904058456421)</td>\n",
       "      <td>(actvity, 0.4389968812465668)</td>\n",
       "      <td>(hamsters, 0.49119776487350464)</td>\n",
       "      <td>(behaviour, 0.4326108694076538)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(sao_paulo, 0.5817981958389282)</td>\n",
       "      <td>(analisys, 0.4498993158340454)</td>\n",
       "      <td>(modeling, 0.45176786184310913)</td>\n",
       "      <td>(depending, 0.4296967387199402)</td>\n",
       "      <td>(rio_de_janeiro, 0.5454093217849731)</td>\n",
       "      <td>(adults, 0.6371790170669556)</td>\n",
       "      <td>(evaluate, 0.4666847288608551)</td>\n",
       "      <td>(action, 0.4334433078765869)</td>\n",
       "      <td>(balbc_mice, 0.47453898191452026)</td>\n",
       "      <td>(activity, 0.3933919668197632)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                brazil                                 study  \\\n",
       "0         (brasil, 0.8688706159591675)         (studies, 0.7355968356132507)   \n",
       "1      (brazilian, 0.8031655550003052)   (investigation, 0.6739801168441772)   \n",
       "2          (brazi, 0.7469620704650879)        (analysis, 0.6443814039230347)   \n",
       "3      (brasilian, 0.6604605913162231)      (evaluation, 0.6117604970932007)   \n",
       "4          (spain, 0.6341298222541809)      (assessment, 0.5354693531990051)   \n",
       "5  (brazilstrongp, 0.6220083236694336)  (investigations, 0.5060980319976807)   \n",
       "6       (portugal, 0.6136013269424438)          (stydy, 0.48788881301879883)   \n",
       "7          (brazils, 0.60157310962677)           (sudy, 0.46877536177635193)   \n",
       "8      (argentina, 0.5932648181915283)          (sutdy, 0.46010395884513855)   \n",
       "9      (sao_paulo, 0.5817981958389282)        (analisys, 0.4498993158340454)   \n",
       "\n",
       "                              analysis                           effects  \\\n",
       "0       (analyses, 0.7738421559333801)      (effect, 0.9310852289199829)   \n",
       "1       (analisys, 0.6831382513046265)   (influence, 0.7686419486999512)   \n",
       "2          (study, 0.6443814039230347)      (impact, 0.6441784501075745)   \n",
       "3     (evaluation, 0.5995726585388184)      (efects, 0.6215373277664185)   \n",
       "4     (assessment, 0.5787420272827148)  (influences, 0.6062849760055542)   \n",
       "5       (analisis, 0.5593183040618896)       (efect, 0.5589128136634827)   \n",
       "6  (investigation, 0.5209058523178101)        (role, 0.4827345013618469)   \n",
       "7        (studies, 0.5072707533836365)     (depends, 0.4525492787361145)   \n",
       "8      (analysys, 0.47804951667785645)    (impacts, 0.43384480476379395)   \n",
       "9      (modeling, 0.45176786184310913)   (depending, 0.4296967387199402)   \n",
       "\n",
       "                              brazilian                           patients  \\\n",
       "0        (brasilian, 0.848153829574585)      (patient, 0.8059606552124023)   \n",
       "1            (brazil, 0.80316561460495)    (patientes, 0.7938013076782227)   \n",
       "2          (brasil, 0.6299118995666504)  (individuals, 0.7883312106132507)   \n",
       "3       (braziliam, 0.6071518659591675)     (subjects, 0.7555750608444214)   \n",
       "4         (spanish, 0.5729133486747742)        (women, 0.7411853075027466)   \n",
       "5       (sao_paulo, 0.5689626932144165)     (children, 0.7381284236907959)   \n",
       "6         (brazils, 0.5603929758071899)      (pacients, 0.718267023563385)   \n",
       "7      (brazillian, 0.5571433305740356)  (outpatients, 0.6770029067993164)   \n",
       "8  (latin_american, 0.5461232662200928)       (patiens, 0.643639862537384)   \n",
       "9  (rio_de_janeiro, 0.5454093217849731)       (adults, 0.6371790170669556)   \n",
       "\n",
       "                            evaluation                          activity  \\\n",
       "0     (assessment, 0.7546509504318237)  (activities, 0.8008769750595093)   \n",
       "1          (study, 0.6117603778839111)   (acitivity, 0.5780574083328247)   \n",
       "2       (analysis, 0.5995725989341736)   (activityof, 0.570565938949585)   \n",
       "3      (evalution, 0.5922452211380005)    (activies, 0.5061926245689392)   \n",
       "4      (assesment, 0.5624517202377319)    (acivity, 0.48496779799461365)   \n",
       "5    (evaluations, 0.5607291460037231)     (activy, 0.47533169388771057)   \n",
       "6  (investigation, 0.5300816297531128)    (activiy, 0.46622419357299805)   \n",
       "7     (evaluating, 0.5208792686462402)  (activites, 0.44755539298057556)   \n",
       "8      (assessing, 0.4701904058456421)     (actvity, 0.4389968812465668)   \n",
       "9       (evaluate, 0.4666847288608551)      (action, 0.4334433078765869)   \n",
       "\n",
       "                                rats                             properties  \n",
       "0           (rat, 0.827140212059021)      (proprieties, 0.6129109859466553)  \n",
       "1         (mice, 0.7445719242095947)         (property, 0.5564204454421997)  \n",
       "2      (rabbits, 0.6112174987792969)     (propertiesof, 0.5214764475822449)  \n",
       "3        (ratsa, 0.5670409202575684)       (propeties, 0.47726237773895264)  \n",
       "4        (mouse, 0.5656639933586121)         (behavior, 0.4641653895378113)  \n",
       "5       (wistar, 0.5301536917686462)  (characteristics, 0.4538622200489044)  \n",
       "6       (rabbit, 0.5016534328460693)        (stability, 0.4474780559539795)  \n",
       "7         (dogs, 0.5006157159805298)    (proprierties, 0.43291914463043213)  \n",
       "8    (hamsters, 0.49119776487350464)        (behaviour, 0.4326108694076538)  \n",
       "9  (balbc_mice, 0.47453898191452026)         (activity, 0.3933919668197632)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = top10.keys())\n",
    "for word in top10.keys():\n",
    "    df[word] = model.wv.most_similar(positive=word)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_name = str(DATA_FILE.split('/')[-1])[:-4] + '.bin'\n",
    "accuracy_file = str(DATA_FILE.split('/')[-1])[:-4] + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(EMBEDDING_OUT_PATH + embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Word2Vec.load(\"../lattes/embedding/embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(EMBEDDING_OUT_PATH + embedding_name,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.evaluate_word_analogies() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.accuracy('/home/antonio/lattes/questions-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(accuracy).to_csv(EMBEDDING_OUT_PATH + accuracy_file, sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
