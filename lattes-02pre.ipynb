{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer # PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "DATA_PATH = './data'\n",
    "PLOT_PATH = './docs/plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 465 ms, sys: 24.9 ms, total: 490 ms\nWall time: 502 ms\n(172165, 3) df shape\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                id                                             titulo   ano\n0  101982954114164  3D reconstruction methods for digital preserva...  2014\n1  101982954114164  3D Viewer Software Build Based on Scanned Synt...  2016\n2  102488447573085  The Globalization Strategy of a High-Tech Mult...  1996\n3  102488447573085  Information Systems as an Instrument of Qualit...  2000\n4  102488447573085  The Experience of a Cardiology Unit in the Dev...  2002",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>titulo</th>\n      <th>ano</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>101982954114164</td>\n      <td>3D reconstruction methods for digital preserva...</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>101982954114164</td>\n      <td>3D Viewer Software Build Based on Scanned Synt...</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>102488447573085</td>\n      <td>The Globalization Strategy of a High-Tech Mult...</td>\n      <td>1996</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>102488447573085</td>\n      <td>Information Systems as an Instrument of Qualit...</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102488447573085</td>\n      <td>The Experience of a Cardiology Unit in the Dev...</td>\n      <td>2002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Data Read\n",
    "data_file = '{}/01pre_lattes.pkl.xz'.format(DATA_PATH)\n",
    "%time df = pd.read_pickle(data_file, compression='xz')\n",
    "print('{} df shape'.format(df.shape))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    172165.000000\nmean         10.482055\nstd           3.873838\nmin           1.000000\n25%           8.000000\n50%          10.000000\n75%          13.000000\nmax          53.000000\nName: wct, dtype: float64"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Descriptive statistics for word count\n",
    "df['wct'] = df['titulo'].str.split().str.len()\n",
    "df.wct.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time: 0.03 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                id                                             titulo  \\\n0  101982954114164  3D reconstruction methods for digital preserva...   \n1  101982954114164  3D Viewer Software Build Based on Scanned Synt...   \n2  102488447573085  The Globalization Strategy of a High-Tech Mult...   \n3  102488447573085  Information Systems as an Instrument of Qualit...   \n4  102488447573085  The Experience of a Cardiology Unit in the Dev...   \n5  102488447573085  Information Systems as an Instrument for Quali...   \n6  102488447573085  Clustering and Categorization Applied to Crypt...   \n7  102488447573085  Criptoanalisys Outwit using Context Sensitive ...   \n8  102488447573085  Cryptographic Algorithm Identification Using M...   \n9  103102694865890  Influence of baroclinic sistems in severe rain...   \n\n                                               clean   ano  wct  \n0  3d reconstruction methods for digital preserva...  2014   11  \n1  3d viewer software build based on scanned synt...  2016   12  \n2  the globalization strategy of a high tech mult...  1996   18  \n3  information systems as an instrument of qualit...  2000   11  \n4  the experience of a cardiology unit in the dev...  2002   17  \n5  information systems as an instrument for quali...  2002    8  \n6  clustering and categorization applied to crypt...  2006    6  \n7  criptoanalisys outwit using context sensitive ...  2016    6  \n8  cryptographic algorithm identification using m...  2016    9  \n9  influence of baroclinic sistems in severe rain...  2011   11  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>titulo</th>\n      <th>clean</th>\n      <th>ano</th>\n      <th>wct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>101982954114164</td>\n      <td>3D reconstruction methods for digital preserva...</td>\n      <td>3d reconstruction methods for digital preserva...</td>\n      <td>2014</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>101982954114164</td>\n      <td>3D Viewer Software Build Based on Scanned Synt...</td>\n      <td>3d viewer software build based on scanned synt...</td>\n      <td>2016</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>102488447573085</td>\n      <td>The Globalization Strategy of a High-Tech Mult...</td>\n      <td>the globalization strategy of a high tech mult...</td>\n      <td>1996</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>102488447573085</td>\n      <td>Information Systems as an Instrument of Qualit...</td>\n      <td>information systems as an instrument of qualit...</td>\n      <td>2000</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102488447573085</td>\n      <td>The Experience of a Cardiology Unit in the Dev...</td>\n      <td>the experience of a cardiology unit in the dev...</td>\n      <td>2002</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>102488447573085</td>\n      <td>Information Systems as an Instrument for Quali...</td>\n      <td>information systems as an instrument for quali...</td>\n      <td>2002</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>102488447573085</td>\n      <td>Clustering and Categorization Applied to Crypt...</td>\n      <td>clustering and categorization applied to crypt...</td>\n      <td>2006</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>102488447573085</td>\n      <td>Criptoanalisys Outwit using Context Sensitive ...</td>\n      <td>criptoanalisys outwit using context sensitive ...</td>\n      <td>2016</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>102488447573085</td>\n      <td>Cryptographic Algorithm Identification Using M...</td>\n      <td>cryptographic algorithm identification using m...</td>\n      <td>2016</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>103102694865890</td>\n      <td>Influence of baroclinic sistems in severe rain...</td>\n      <td>influence of baroclinic sistems in severe rain...</td>\n      <td>2011</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Normalização\n",
    "\n",
    "df.insert(2, 'clean', df.titulo)\n",
    "\n",
    "def remove_separation(doc):\n",
    "    table = doc.maketrans('-/', '  ')\n",
    "    return doc.translate(table)\n",
    "\n",
    "def strip_ponct(doc):\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    return doc.translate(table)\n",
    "\n",
    "def normaliza(doc):\n",
    "    doc = remove_separation(doc)\n",
    "    doc = strip_ponct(doc)\n",
    "    doc = doc.lower()\n",
    "    return doc\n",
    "\n",
    "t = time()\n",
    "df.clean = df.clean.apply(normaliza)\n",
    "\n",
    "print('Time: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time: 1.23 mins\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                id                                             titulo  \\\n0  101982954114164  3D reconstruction methods for digital preserva...   \n1  101982954114164  3D Viewer Software Build Based on Scanned Synt...   \n2  102488447573085  The Globalization Strategy of a High-Tech Mult...   \n3  102488447573085  Information Systems as an Instrument of Qualit...   \n4  102488447573085  The Experience of a Cardiology Unit in the Dev...   \n5  102488447573085  Information Systems as an Instrument for Quali...   \n6  102488447573085  Clustering and Categorization Applied to Crypt...   \n7  102488447573085  Criptoanalisys Outwit using Context Sensitive ...   \n8  102488447573085  Cryptographic Algorithm Identification Using M...   \n9  103102694865890  Influence of baroclinic sistems in severe rain...   \n\n                                               clean   ano  wct  \n0  [3d, reconstruct, method, digit, preserv, cult...  2014   11  \n1  [3d, viewer, softwar, build, base, scan, synth...  2016   12  \n2  [global, strategi, high, tech, multin, corpor,...  1996   18  \n3  [inform, system, instrument, qualiti, program,...  2000   11  \n4  [experi, cardiolog, unit, develop, qualiti, pr...  2002   17  \n5     [inform, system, instrument, qualiti, program]  2002    8  \n6            [cluster, categor, appli, cryptanalysi]  2006    6  \n7  [criptoanalisi, outwit, use, context, sensit, ...  2016    6  \n8  [cryptograph, algorithm, identif, use, machin,...  2016    9  \n9  [influenc, baroclin, sistem, sever, rainstorm,...  2011   11  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>titulo</th>\n      <th>clean</th>\n      <th>ano</th>\n      <th>wct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>101982954114164</td>\n      <td>3D reconstruction methods for digital preserva...</td>\n      <td>[3d, reconstruct, method, digit, preserv, cult...</td>\n      <td>2014</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>101982954114164</td>\n      <td>3D Viewer Software Build Based on Scanned Synt...</td>\n      <td>[3d, viewer, softwar, build, base, scan, synth...</td>\n      <td>2016</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>102488447573085</td>\n      <td>The Globalization Strategy of a High-Tech Mult...</td>\n      <td>[global, strategi, high, tech, multin, corpor,...</td>\n      <td>1996</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>102488447573085</td>\n      <td>Information Systems as an Instrument of Qualit...</td>\n      <td>[inform, system, instrument, qualiti, program,...</td>\n      <td>2000</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102488447573085</td>\n      <td>The Experience of a Cardiology Unit in the Dev...</td>\n      <td>[experi, cardiolog, unit, develop, qualiti, pr...</td>\n      <td>2002</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>102488447573085</td>\n      <td>Information Systems as an Instrument for Quali...</td>\n      <td>[inform, system, instrument, qualiti, program]</td>\n      <td>2002</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>102488447573085</td>\n      <td>Clustering and Categorization Applied to Crypt...</td>\n      <td>[cluster, categor, appli, cryptanalysi]</td>\n      <td>2006</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>102488447573085</td>\n      <td>Criptoanalisys Outwit using Context Sensitive ...</td>\n      <td>[criptoanalisi, outwit, use, context, sensit, ...</td>\n      <td>2016</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>102488447573085</td>\n      <td>Cryptographic Algorithm Identification Using M...</td>\n      <td>[cryptograph, algorithm, identif, use, machin,...</td>\n      <td>2016</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>103102694865890</td>\n      <td>Influence of baroclinic sistems in severe rain...</td>\n      <td>[influenc, baroclin, sistem, sever, rainstorm,...</td>\n      <td>2011</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Stopwords / Lemma\n",
    "\n",
    "default_stemmer = SnowballStemmer('english')\n",
    "default_lemmatizer = WordNetLemmatizer()\n",
    "default_stopwords = stopwords.words('english')\n",
    "\n",
    "noise_file = open('{}/extra/noise.txt'.format(DATA_PATH),'r')\n",
    "noise = noise_file.read().splitlines()\n",
    "\n",
    "def remove_stopwords(doc, stop_words=default_stopwords):\n",
    "    words = [w for w in doc if not w in stop_words]\n",
    "    return words\n",
    "\n",
    "def lemm_text(doc, lemmatizer=default_lemmatizer):\n",
    "    words = [lemmatizer.lemmatize(w, pos='v') for w in doc]\n",
    "    return words\n",
    "\n",
    "def stem_text(doc, stemmer=default_stemmer):\n",
    "    words = [stemmer.stem(w) for w in doc]\n",
    "    return words\n",
    "\n",
    "def remove_noise(doc):\n",
    "    words = [w for w in doc if not w in noise]\n",
    "    return words\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = word_tokenize(doc)\n",
    "    doc = remove_stopwords(doc)\n",
    "    doc = lemm_text(doc)\n",
    "    doc = stem_text(doc)\n",
    "    doc = [w for w in doc if len(w) > 1]\n",
    "    doc = remove_noise(doc)\n",
    "    return doc\n",
    "\n",
    "t = time()\n",
    "df.clean = df.clean.apply(preprocess)\n",
    "print('Time: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    172165.000000\nmean          8.013772\nstd           2.750311\nmin           0.000000\n25%           6.000000\n50%           8.000000\n75%          10.000000\nmax          48.000000\nName: wcc, dtype: float64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df['wcc'] = df.apply(lambda row: len(row['clean']), axis=1)\n",
    "df.wcc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['wcc']==0].index, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs Plot foo's\n",
    "\n",
    "# Plot a hist of the word counts\n",
    "def graph_hist(df, year=None):\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    plt.hist(df.wct, bins=20, color='#60505C')\n",
    "\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.xlabel('Word Count', fontsize=12)\n",
    "    #plt.yticks(np.arange(0, 2000, 200))\n",
    "    #plt.xticks(np.arange(0, 600, 50))\n",
    "\n",
    "    if year != None:\n",
    "        plt.title('{} Docs Word Count'.format(year), fontsize=16)\n",
    "        path = '{}/{}'.format(PLOT_PATH,year)\n",
    "        Path(path).mkdir(exist_ok=True)\n",
    "    else:\n",
    "        plt.title('Docs Word Count', fontsize=16)\n",
    "        path = PLOT_PATH\n",
    "\n",
    "    file_name = '{}/hist.png'.format(path)\n",
    "    fig.savefig(file_name, dpi=fig.dpi, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot a boxplot of the word counts\n",
    "def graph_boxplot(df, year=None):\n",
    "    fig = plt.figure(figsize=(4,9))\n",
    "\n",
    "    sns.boxplot(df.wct, orient='v', width=.5, color='#ff8080')\n",
    "\n",
    "    plt.ylabel(\"Word Count\", fontsize=12)\n",
    "    #plt.yticks(np.arange(0, 2700, 100))\n",
    "\n",
    "    if year != None:\n",
    "        plt.title('{} Docs Word Count'.format(year), fontsize=16)\n",
    "        path = '{}/{}'.format(PLOT_PATH,year)\n",
    "        Path(path).mkdir(exist_ok=True)\n",
    "    else:\n",
    "        plt.title('Docs Word Count', fontsize=16)\n",
    "        path = PLOT_PATH\n",
    "\n",
    "    file_name = '{}/box_plot.png'.format(path)\n",
    "    fig.savefig(file_name, dpi=fig.dpi, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def get_top20(df):\n",
    "    p_text = df.clean\n",
    "    p_text = [item for sublist in p_text for item in sublist]\n",
    "    df_top_20 = pd.DataFrame(\n",
    "        Counter(p_text).most_common(20),\n",
    "        columns=['word', 'frequency']\n",
    "    )\n",
    "    return p_text, df_top_20\n",
    "\n",
    "# Plot a bar chart for the top 20 most frequently occuring words\n",
    "def graph_top20(df_top20, year=None):\n",
    "    fig = plt.figure(figsize=(20,7))\n",
    "    g = sns.barplot(x='word', y='frequency', data=df_top20, palette='GnBu_d')\n",
    "    g.set_xticklabels(g.get_xticklabels(),rotation=45,fontsize=14)\n",
    "\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel('Words', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "    if year != None:\n",
    "        plt.title('{} Top 20 Words'.format(year), fontsize=17)\n",
    "        path = '{}/{}'.format(PLOT_PATH,year)\n",
    "        Path(path).mkdir(exist_ok=True)\n",
    "    else:\n",
    "        plt.title('Top 20 Words', fontsize=17)\n",
    "        path = PLOT_PATH\n",
    "\n",
    "    file_name = '{}/top_words.png'.format(path)\n",
    "    fig.savefig(file_name, dpi=fig.dpi, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time: 0.83 mins\n"
    }
   ],
   "source": [
    "# Save\n",
    "\n",
    "t = time()\n",
    "pre_file = '{}/02pre_lattes.pkl.xz'.format(DATA_PATH)\n",
    "df.to_pickle(pre_file, compression='xz')\n",
    "\n",
    "# Get the top 20 most common words among all the articles\n",
    "p_text, df_top20 = get_top20(df)\n",
    "\n",
    "graph_hist(df)\n",
    "graph_boxplot(df)\n",
    "graph_top20(df_top20)\n",
    "\n",
    "# Get the number of unique words after processing\n",
    "#num_unique_words = len(set(p_text))\n",
    "#num_unique_words\n",
    "del p_text, df_top20\n",
    "\n",
    "for year in range(2008,2019):\n",
    "\n",
    "    df_year = df.loc[df['ano']==year]\n",
    "    df_year.drop(['ano'], axis=1, inplace=True)\n",
    "\n",
    "    p_text, df_top20 = get_top20(df_year)\n",
    "\n",
    "    graph_hist(df_year,year)\n",
    "    graph_boxplot(df_year,year)\n",
    "    graph_top20(df_top20,year)\n",
    "\n",
    "    pkl_file = '{}/{}_lattes.pkl.xz'.format(DATA_PATH,year)\n",
    "    df_year.to_pickle(pkl_file, compression='xz')\n",
    "    del df_year, p_text, df_top20\n",
    "\n",
    "print('Time: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python38264bitvenvvenv2bbc39647f214cc383d5c83f858d10a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}