{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import langid\n",
    "import multiprocessing\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "BASE_DIR = '/home/antonio/lattes_base/Collection'\n",
    "N_THREADS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(doc, dout):\n",
    "    author = pd.DataFrame(columns=['author_id', 'author_name', 'author_ref', 'doctorate', 'paper_issn', 'paper_ano', 'paper', 'paper_home_page'])\n",
    "    \n",
    "    \n",
    "    ### get articles by authors without id\n",
    "    try:\n",
    "        author_id = doc['CURRICULO-VITAE']['@NUMERO-IDENTIFICADOR']\n",
    "    except:\n",
    "        author_id = None\n",
    "\n",
    "    ### get author info\n",
    "    try:\n",
    "        artigos = doc['CURRICULO-VITAE']['PRODUCAO-BIBLIOGRAFICA']['ARTIGOS-PUBLICADOS']['ARTIGO-PUBLICADO']\n",
    "        author_name = doc['CURRICULO-VITAE']['DADOS-GERAIS']['@NOME-EM-CITACOES-BIBLIOGRAFICAS']\n",
    "        author_complete_name = doc['CURRICULO-VITAE']['DADOS-GERAIS']['@NOME-COMPLETO']\n",
    "    except:\n",
    "        return author\n",
    "    \n",
    "    list_artigos = []\n",
    "    papers = {}\n",
    "    \n",
    "    ###get articles\n",
    "    if type(artigos) == list: ### if the author has several articles\n",
    "        for artigo in artigos:   \n",
    "            try:\n",
    "                if(artigo['DADOS-BASICOS-DO-ARTIGO']['@IDIOMA'] == \"Inglês\"):\n",
    "                    papers['paper'] = artigo['DADOS-BASICOS-DO-ARTIGO']['@TITULO-DO-ARTIGO']\n",
    "                    papers['paper_issn'] = artigo['DETALHAMENTO-DO-ARTIGO']['@ISSN']\n",
    "                    papers['paper_ano'] = artigo['DADOS-BASICOS-DO-ARTIGO']['@ANO-DO-ARTIGO']\n",
    "                    papers['paper_home_page'] = artigo['DADOS-BASICOS-DO-ARTIGO']['@HOME-PAGE-DO-TRABALHO']       \n",
    "                    string = ''\n",
    "                    for autores in artigo['AUTORES']: ##get co-authors\n",
    "                        try:\n",
    "                            string += 'ordem: ' + str(autores['@ORDEM-DE-AUTORIA']) + '\\n'\n",
    "                            string += 'name: ' + autores['@NOME-COMPLETO-DO-AUTOR'] + '\\n'\n",
    "                            string += 'name_ref ' + autores['@NOME-PARA-CITACAO']  + '\\n'\n",
    "                        except:\n",
    "                            pass\n",
    "                    papers['coauthors'] = string\n",
    "                    list_artigos.append(copy.deepcopy(papers))\n",
    "            except:\n",
    "                pass\n",
    "    else: ## or only one articles\n",
    "        if(artigos['DADOS-BASICOS-DO-ARTIGO']['@IDIOMA'] == \"Inglês\"):\n",
    "                    papers['paper'] = artigos['DADOS-BASICOS-DO-ARTIGO']['@TITULO-DO-ARTIGO']\n",
    "                    papers['paper_issn'] = artigos['DETALHAMENTO-DO-ARTIGO']['@ISSN']\n",
    "                    papers['paper_ano'] = artigos['DADOS-BASICOS-DO-ARTIGO']['@ANO-DO-ARTIGO']\n",
    "                    papers['paper_home_page'] = artigos['DADOS-BASICOS-DO-ARTIGO']['@HOME-PAGE-DO-TRABALHO']       \n",
    "                    string = ''\n",
    "                    for autores in artigos['AUTORES']: ##get co-authors\n",
    "                        try:\n",
    "                            string += 'ordem: ' + str(autores['@ORDEM-DE-AUTORIA']) + '\\n'\n",
    "                            string += 'name: ' + autores['@NOME-COMPLETO-DO-AUTOR'] + '\\n'\n",
    "                            string += 'name_ref ' + autores['@NOME-PARA-CITACAO']  + '\\n'\n",
    "                        except:\n",
    "                            pass\n",
    "                    papers['coauthors'] = string\n",
    "                    list_artigos.append(copy.deepcopy(papers))\n",
    "\n",
    "    ### fills the dataframe\n",
    "    for index in range(len(list_artigos)):\n",
    "        author.loc[index] = (author_id, author_complete_name, author_name, dout, list_artigos[index]['paper_issn'], list_artigos[index]['paper_ano'], list_artigos[index]['paper'], list_artigos[index]['paper_home_page'])\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(doc, courses):\n",
    "    author = pd.DataFrame(columns=['author_id', 'author_name', 'author_ref', 'doctorate', 'paper_issn', 'paper_ano', 'paper', 'paper_home_page'])\n",
    "    \n",
    "    ### checks if the author has a doctorate\n",
    "    try :\n",
    "        dout  = doc['CURRICULO-VITAE']['DADOS-GERAIS']['FORMACAO-ACADEMICA-TITULACAO']['DOUTORADO']\n",
    "    except:\n",
    "        dout = None\n",
    "    \n",
    "    if dout:\n",
    "        if type(dout) == list: ### if the author has several doctorates\n",
    "            l_dout = [x['@NOME-CURSO'] for x in dout]\n",
    "            for value in l_dout:\n",
    "                if value and value in courses:\n",
    "                    dout = \", \".join(l_dout)\n",
    "                    author = get_info(doc, dout)\n",
    "                    break\n",
    "                \n",
    "        elif dout['@NOME-CURSO'] and dout['@NOME-CURSO'] in courses: ### or only one doctorate\n",
    "            dout = dout['@NOME-CURSO'] \n",
    "            author = get_info(doc, dout)\n",
    "            \n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(files, return_num, return_dict, courses):\n",
    "    author = pd.DataFrame(columns=['author_id', 'author_name', 'author_ref', 'doctorate', 'paper_issn', 'paper_ano', 'paper', 'paper_home_page'])\n",
    "    dataframes = []\n",
    "    dataframes.append(author.copy())\n",
    "    \n",
    "    n_files = len(files)\n",
    "    for index, file in enumerate(files, start=0):\n",
    "        with open(file + '/curriculo.xml', encoding=\"ISO-8859-1\") as fd:\n",
    "            doc = xmltodict.parse(fd.read())\n",
    "        new_df = get_author(doc, courses)\n",
    "        if not new_df.empty:\n",
    "            dataframes.append(new_df)\n",
    "        clear_output(wait=True)\n",
    "        print(str(\"%.2f\" % (index * 100 / n_files /4)) + '%')\n",
    "        \n",
    "    author = pd.concat(dataframes)\n",
    "    return_dict[return_num] = author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = []\n",
    "\n",
    "for folder in os.listdir(BASE_DIR):\n",
    "    path = os.path.join(BASE_DIR, folder)\n",
    "    if(os.path.isdir(path) == True and not folder.startswith('.')):\n",
    "        for files in os.listdir(path):\n",
    "            if not files.startswith('.'):\n",
    "                file = os.path.join(path, files)\n",
    "                files_list.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open('courses.txt', 'r')\n",
    "courses = file.read()\n",
    "file.close()\n",
    "courses = re.split(', |\\n',courses)\n",
    "\n",
    "n_threads = N_THREADS\n",
    "n_data = len(files_list)\n",
    "if(n_data%n_threads == 0):\n",
    "        division = int(n_data/n_threads)\n",
    "else:\n",
    "    division = int(n_data/n_threads)+1\n",
    "    \n",
    "manager = multiprocessing.Manager()\n",
    "return_dict = manager.dict()\n",
    "jobs = []\n",
    "for i in range(n_threads):\n",
    "    init = i*division\n",
    "    end = (i+1)*division\n",
    "    p = multiprocessing.Process(target=worker, args=(files_list[init:end], i, return_dict, courses))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "for proc in jobs:\n",
    "    proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataframe and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = pd.DataFrame(columns=['author_id', 'author_name', 'author_ref', 'doctorate', 'paper_issn', 'paper_ano', 'paper', 'paper_home_page'])\n",
    "dataframes = []\n",
    "dataframes.append(author.copy())\n",
    "for value in return_dict.values():\n",
    "    dataframes.append(value)\n",
    "author = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author.to_csv('data.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''author = {}\n",
    "author_inf = {}\n",
    "\n",
    "author_name = doc['CURRICULO-VITAE']['DADOS-GERAIS']['@NOME-EM-CITACOES-BIBLIOGRAFICAS']\n",
    "author_id = doc['CURRICULO-VITAE']['@NUMERO-IDENTIFICADOR']\n",
    "author_complete_name = doc['CURRICULO-VITAE']['DADOS-GERAIS']['@NOME-COMPLETO']\n",
    "\n",
    "author_inf['id'] = author_id\n",
    "author_inf['name'] = author_complete_name\n",
    "author_inf['ref_name'] = author_name\n",
    "author['informacoes'] = author_inf\n",
    "\n",
    "artigos = doc['CURRICULO-VITAE']['PRODUCAO-BIBLIOGRAFICA']['ARTIGOS-PUBLICADOS']['ARTIGO-PUBLICADO']\n",
    "pub = []\n",
    "for artigo in artigos:\n",
    "    if(artigo['DADOS-BASICOS-DO-ARTIGO']['@IDIOMA'] == \"Inglês\"):\n",
    "        paper = {}\n",
    "        paper['titulo'] = artigo['DADOS-BASICOS-DO-ARTIGO']['@TITULO-DO-ARTIGO']\n",
    "        paper['issn'] = artigo['DETALHAMENTO-DO-ARTIGO']['@ISSN']\n",
    "        paper['ano'] = artigo['DADOS-BASICOS-DO-ARTIGO']['@ANO-DO-ARTIGO']\n",
    "        paper['home_page'] = artigo['DADOS-BASICOS-DO-ARTIGO']['@HOME-PAGE-DO-TRABALHO']       \n",
    "        \n",
    "        \n",
    "        #print(artigo['DADOS-BASICOS-DO-ARTIGO']['@TITULO-DO-ARTIGO'])\n",
    "        #print(artigo['DETALHAMENTO-DO-ARTIGO']['@ISSN'])\n",
    "        #print(artigo['DADOS-BASICOS-DO-ARTIGO']['@HOME-PAGE-DO-TRABALHO'])\n",
    "        #print(artigo['DADOS-BASICOS-DO-ARTIGO']['@ANO-DO-ARTIGO'])\n",
    "        #authors = []\n",
    "        #authors_inf = {}\n",
    "        #for autores in artigo['AUTORES']:            \n",
    "        #    authors_inf['nome'] = autores['@NOME-COMPLETO-DO-AUTOR']\n",
    "        #    authors_inf['name_ref']  = autores['@NOME-PARA-CITACAO']\n",
    "        #    authors_inf['ordem'] = autores['@ORDEM-DE-AUTORIA']\n",
    "            #authors[autores['@NOME-PARA-CITACAO']] = autors_inf.copy()\n",
    "        #    authors.append(copy.deepcopy(authors_inf))\n",
    "            \n",
    "            #print(autores['@NOME-COMPLETO-DO-AUTOR'])\n",
    "            #print(autores['@NOME-PARA-CITACAO'])\n",
    "            #print(autores['@ORDEM-DE-AUTORIA'])\n",
    "            \n",
    "        #paper['autores'] = copy.deepcopy(authors)\n",
    "        pub.append(copy.deepcopy(paper))\n",
    "        print('\\n\\n')\n",
    "author['artigos'] = pub[:]'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
