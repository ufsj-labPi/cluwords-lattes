{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_year = 2017\n",
    "input = './data/out/%dpreprocess.csv.xz' % select_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3055 entries, 0 to 3054\nData columns (total 1 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   titulo  3055 non-null   object\ndtypes: object(1)\nmemory usage: 24.0+ KB\n"
    }
   ],
   "source": [
    "df = pd.read_csv(input, compression='xz')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "df['titulo'] = df['titulo'].map(lambda x: ' '.join([stemmer.stem(y) for y in x.split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('exploit', 566),\n ('locat', 890),\n ('direct', 453),\n ('bas', 138),\n ('discoveri', 455),\n ('gold', 674),\n ('standard', 1496),\n ('social', 1445),\n ('media', 935),\n ('corpus', 348),\n ('urban', 1651),\n ('issu', 824),\n ('framework', 629),\n ('spatial', 1478),\n ('analyt', 65),\n ('use', 1654),\n ('heterogen', 706),\n ('data', 383),\n ('sourc', 1468),\n ('social media', 1446)]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Initialize the vectorizer with new settings and check the new vocabulary length\n",
    "cvec = CountVectorizer(stop_words='english', min_df=.0025, max_df=.5, ngram_range=(1,2))\n",
    "cvec.fit(df['titulo'])\n",
    "list(islice(cvec.vocabulary_.items(), 20))\n",
    "#len(cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1738"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sparse matrix shape: (3055, 1738)\nnonzero count: 52768\nsparsity: 0.99%\n"
    }
   ],
   "source": [
    "cvec_counts = cvec.transform(df['titulo'])\n",
    "print('sparse matrix shape:', cvec_counts.shape)\n",
    "print('nonzero count:', cvec_counts.nnz)\n",
    "print('sparsity: %.2f%%' % (100.0 * cvec_counts.nnz / (cvec_counts.shape[0] * cvec_counts.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           term  occurrences\n1654        use         1131\n978       model          856\n1031    network          765\n61      analysi          706\n144        base          636\n383        data          592\n138         bas          568\n81     approach          522\n1520      studi          472\n46    algorithm          433\n856       learn          431\n1449    softwar          385\n79       applic          368\n1205    problem          356\n547       evalu          353\n950      method          334\n430      detect          320\n1208    process          308\n1001      multi          299\n1086      optim          296",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>occurrences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1654</th>\n      <td>use</td>\n      <td>1131</td>\n    </tr>\n    <tr>\n      <th>978</th>\n      <td>model</td>\n      <td>856</td>\n    </tr>\n    <tr>\n      <th>1031</th>\n      <td>network</td>\n      <td>765</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>analysi</td>\n      <td>706</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>base</td>\n      <td>636</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>data</td>\n      <td>592</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>bas</td>\n      <td>568</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>approach</td>\n      <td>522</td>\n    </tr>\n    <tr>\n      <th>1520</th>\n      <td>studi</td>\n      <td>472</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>algorithm</td>\n      <td>433</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>learn</td>\n      <td>431</td>\n    </tr>\n    <tr>\n      <th>1449</th>\n      <td>softwar</td>\n      <td>385</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>applic</td>\n      <td>368</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>problem</td>\n      <td>356</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>evalu</td>\n      <td>353</td>\n    </tr>\n    <tr>\n      <th>950</th>\n      <td>method</td>\n      <td>334</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>detect</td>\n      <td>320</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>process</td>\n      <td>308</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>multi</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>1086</th>\n      <td>optim</td>\n      <td>296</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "occ = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist()\n",
    "counts_df = pd.DataFrame({'term': cvec.get_feature_names(), 'occurrences': occ})\n",
    "counts_df.sort_values(by='occurrences', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<3055x1738 sparse matrix of type '<class 'numpy.float64'>'\n\twith 52768 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "transformed_weights = transformer.fit_transform(cvec_counts)\n",
    "transformed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           term    weight\n1654        use  0.030496\n978       model  0.026791\n1031    network  0.024483\n61      analysi  0.022708\n383        data  0.020849\n144        base  0.020660\n138         bas  0.018881\n81     approach  0.018515\n1520      studi  0.016754\n46    algorithm  0.016510\n856       learn  0.016475\n1205    problem  0.014730\n1449    softwar  0.014233\n950      method  0.014200\n79       applic  0.014138\n430      detect  0.013297\n547       evalu  0.013149\n436     develop  0.012719\n1208    process  0.012612\n298      comput  0.012434",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1654</th>\n      <td>use</td>\n      <td>0.030496</td>\n    </tr>\n    <tr>\n      <th>978</th>\n      <td>model</td>\n      <td>0.026791</td>\n    </tr>\n    <tr>\n      <th>1031</th>\n      <td>network</td>\n      <td>0.024483</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>analysi</td>\n      <td>0.022708</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>data</td>\n      <td>0.020849</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>base</td>\n      <td>0.020660</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>bas</td>\n      <td>0.018881</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>approach</td>\n      <td>0.018515</td>\n    </tr>\n    <tr>\n      <th>1520</th>\n      <td>studi</td>\n      <td>0.016754</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>algorithm</td>\n      <td>0.016510</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>learn</td>\n      <td>0.016475</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>problem</td>\n      <td>0.014730</td>\n    </tr>\n    <tr>\n      <th>1449</th>\n      <td>softwar</td>\n      <td>0.014233</td>\n    </tr>\n    <tr>\n      <th>950</th>\n      <td>method</td>\n      <td>0.014200</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>applic</td>\n      <td>0.014138</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>detect</td>\n      <td>0.013297</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>evalu</td>\n      <td>0.013149</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>develop</td>\n      <td>0.012719</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>process</td>\n      <td>0.012612</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>comput</td>\n      <td>0.012434</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "weights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Topic 1: effici,energi,design,generat,simul,improv,low,parallel,high,perform\nTopic 2: code,softwar ecosystem,requir,ecosystem,softwar develop,studi,project,softwar engin,engin,softwar\nTopic 3: rout,search,solv,schedul problem,schedul,heurist,genet algorithm,genet,algorithm,problem\nTopic 4: vehicular,optic,alloc,optic network,traffic,rout,defin,servic,manag,network\nTopic 5: deep,use,recognit,artifici neural,artifici,convolut neural,convolut,network,neural network,neural\nTopic 6: deep,teach,virtual learn,machin learn,machin,learn object,educ,environ,learn environ,learn\nTopic 7: data stream,scientif workflow,open data,visual,workflow,scientif,big data,open,big,data\nTopic 8: strategi,compar studi,educ,use,studi brazilian,analysi,sustain,case studi,case,studi\nTopic 9: bas model,driven,model use,data,estim,simul,integr,conceptu,model base,model\nTopic 10: rank,complex,number,larg,threshold,convex,modal,color,edge,graph\nTopic 11: concept,approach,analysi base,scientif,measur,network,social network,social,network analysi,analysi\nTopic 12: measur,gpu,evalu,spatial,evalu use,3d,predict,estim,techniqu,use\nTopic 13: monitor,network use,underwat,channel,sink,industri,sensor network,wireless sensor,wireless,sensor\nTopic 14: requir,design,systemat map,systemat review,map,systemat literatur,literatur review,literatur,review,systemat\nTopic 15: approach,mobil cloud,perform evalu,privaci,evalu,secur,comput,servic,cloud comput,cloud\nTopic 16: analysi base,cellular,algorithm base,recognit,video,improv,approach base,model base,function,base\nTopic 17: river,region,sugarcan,impact,manag,plant,environment,assess,water,brazil\nTopic 18: develop process,requir,goal,decis,research,pattern,process model,busi process,busi,process\nTopic 19: methodolog,develop process,driven,risk,new,challeng,agil,simul,softwar develop,develop\nTopic 20: bas learn,manag,extract,bas model,attack,agent bas,agent,monitor,bas approach,bas\nTopic 21: valid,code,assess,experiment,suit,bas test,test case,impact,softwar test,test\nTopic 22: immers,train,virtual environ,3d,augment realiti,augment,environ,virtual realiti,realiti,virtual\nTopic 23: estim distribut,hybrid,learn object,metaheurist,object optim,multi ag,ag,multi object,object,multi\nTopic 24: implement,proxim,element,numer,element method,point,method appli,equat,appli,method\nTopic 25: vehicl rout,rout,rout problem,approach,unman aerial,aerial vehicl,aerial,multipl,unman,vehicl\nTopic 26: strategi,time,video,low,gpu,gpu bas,schedul,real tim,real,tim\nTopic 27: transpar,educ,visual,project,teach,design,manag,evalu,tool,game\nTopic 28: eeg,fault,individu,classif,ensembl,diagnosi,classifi,featur select,select,featur\nTopic 29: imag process,textur,imag segment,reconstruct,unsupervis,imag use,spectral,automat,segment,imag\nTopic 30: inform,annot,open,recommend,semant,languag,text,portugues,approach,ontolog\nTopic 31: offshor,topolog,object optim,use particl,particl,particl swarm,swarm optim,swarm,optim algorithm,optim\nTopic 32: outlier,conflict,reactiv,anomali detect,approach,detect use,communiti,communiti detect,anomali,detect\nTopic 33: chao,interfac,distribut,mobil robot,voltag,format,autonom,fuzzi,robot,control\nTopic 34: brazilian portugues,capac,activ,govern,research,public,traffic,urban,plan,brazilian\nTopic 35: ray,enhanc,solar,approach,fuzzi,seri forecast,forecast,time seri,seri,time\nTopic 36: design,search,base,approach,industri,line architectur,softwar product,product line,line,product\nTopic 37: genome wid,wid,strain,express,genom sequenc,cattl,associ,sequenc,genom,gene\nTopic 38: augment,improv,offload,mobil cloud,devic,support,mobil devic,mobil applic,applic,mobil\nTopic 39: p2p,construct,constrain,appli,fuzzi cluster,simul,data stream,fuzzi,stream,cluster\nTopic 40: experiment,stabil,correl,effect,kinet,electron,protein structur,protein,properti,structur\nTopic 41: context awar,middlewar,awar,secur,privaci,context,inform,internet thing,thing,internet\nTopic 42: type,shortest,classifi,transvers,optimum,path forest,optimum path,forest,power,path\nTopic 43: inform,diseas,patient,framework,semant,electron health,health record,electron,record,health\nTopic 44: behavior,research,na,dos,brasil,um,uma,em,para,da\nTopic 45: defin,introduct,induct,law,interact visual,user,human,multimod,visual,interact\nTopic 46: enterpris architectur,multiag,modular,devic,refer architectur,constraint,refer,smart,specif,architectur\nTopic 47: probabilist,techniqu,relat,integ program,linear,integ,educ,complex,logic,program\nTopic 48: organ,hierarch,deep learn,label,imag classif,textur,deep,data classif,classif use,classif\nTopic 49: parallel,p2p,self,stream,spark,entiti,match,dynam,effici,adapt\nTopic 50: stereo,multipl,heterogen,processor,align,sequenc,linear,type,parallel,comput\n"
    }
   ],
   "source": [
    "#pd.DataFrame(transformed_weights.toarray(), columns=cvec.get_feature_names())\n",
    "\n",
    "nmf = NMF(n_components=50, solver=\"mu\")\n",
    "idx_to_word = np.array(cvec.get_feature_names())\n",
    "W = nmf.fit_transform(transformed_weights)\n",
    "H = nmf.components_\n",
    "\n",
    "for i, topic in enumerate(H):\n",
    "    print(\"Topic {}: {}\".format(i + 1, \",\".join([str(x) for x in idx_to_word[topic.argsort()[-10:]]])))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenv2bbc39647f214cc383d5c83f858d10a1",
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}